
import re
import os
import json
from functools import cmp_to_key

# Script that reads all crash results in results-crashes/ and
# prints out all the unique backtraces that we have.

# Crashes with some additional metadata
unique_metacrashes = []

def fname_id(name:str) -> int:
    # Format of input files is:
    # r'inp\.\d+'
    m = re.match(r'.+\.(\d+)', name)
    return int(m.group(1))

def metacrash_comparator(c1, c2) -> int:
    # Sorts the metacrashes.
    # The most recently found *new* crashes are displayed last.
    # Basically it is an ascending sort on `fname_id`
    # Assumes that filenames are already sorted in ascending order
    return fname_id(c1['files'][0]) - fname_id(c2['files'][0])

def crashes_are_equal(crash: dict, other: dict):
    crash_bts = crash['output']['bt']
    other_bts = other['output']['bt']
    if len(crash_bts) != len(other_bts):
        return False
    for i in range(len(crash_bts)):
        # Between backtraces, the function name and location within the source file must be identical for the
        # crashes to be identical.
        if crash_bts[i]['funcname'] != other_bts[i]['funcname']:
            return False
        if crash_bts[i]['filename'] != other_bts[i]['filename']:
            return False
    return True

def add_crash(metacrashes: list[dict], crash: dict, fname):
    for other_metacrash in metacrashes:
        if crashes_are_equal(crash, other_metacrash['crash']):
            other_metacrash['count'] += 1
            other_metacrash['files'].append(fname)
            return False
    metacrashes.append({
        'crash': crash,
        'files': [fname],
        'count': 1
    })
    return True


last_fuzzer_iteration=-1
for fname in sorted(os.listdir('results-crashes'), key=fname_id): # sorting helps in case we want the latest results only
    try:
        with open('results-crashes/' + fname) as f:
            data = json.load(f)
    except json.JSONDecodeError:
        continue
    add_crash(unique_metacrashes, data, fname)
    if fname_id(fname) > last_fuzzer_iteration:
        last_fuzzer_iteration = fname_id(fname)
    
    for trace in data['output']['bt']:
        if 'tsearch' in trace['raw']:
            print(data)
            print(fname)
            print('Fuzzing DONE!')
            exit(0)

for metacrash in unique_metacrashes:
    metacrash['files'] = sorted(metacrash['files'], key=fname_id) # ascending sort of filenames
unique_metacrashes = sorted(unique_metacrashes, key=cmp_to_key(metacrash_comparator))
print('Detailed results:')
for crash in unique_metacrashes:
    print('Count: {}'.format(crash['count']))
    print('Files: ' + ', '.join(crash['files']))
    for trace in crash['crash']['output']['bt']:
        print(trace['raw'])
    print()

print(f'last_fuzzer_iteration: {last_fuzzer_iteration}')
print(f'total unique crashes : {len(unique_metacrashes)}')
